---
layout: single
title: "ESG 자동 보고서 프로젝트"
date: 2026-01-19 15:00:00 +0900
categories: [dev]
tags: [jekyll, github-pages, minimal-mistakes]
---

![fig1]({{ "/assets/images/posts/2026/260119-esg/hynix-report.png" | relative_url }})

![fig1]({{ "/assets/images/posts/2026/260119-esg/issue-pool.png" | relative_url }})


esg 중대성 평가를 하는 AI 모델을 만들고 싶어. 첨부한 계산식을 사용하는 AI 모델이야. 현재 랭그래프에 스타 토폴로지 로 엑사원 , 코일렉트라 가 노드로 구성되어 있어. postgre 와 pgvector 를 같이 사용하고 , 화면은 넥스트 js 야. 개발 기간은 3주이내로 할 거야 . 진행 과정을 너가 PM 으로서 내게 칸반보드로 구성해줘.


아래 내용은 **그대로 Jekyll Markdown(md) 파일에 붙여넣기 좋은 형태**로 정리해드렸습니다. (표는 GitHub Pages/Jekyll에서 잘 렌더링되도록 정돈했고, 불필요한 강조는 최소화했습니다.)

---

# 3주 MVP 칸반 보드 (KSA 중대성 평가 AI)

“3주 내 MVP 완성”을 목표로, KSA 중대성 평가(핵심 이슈 분석) 계산식 기반 + LangGraph 스타 토폴로지(EXAONE/KoELECTRA) + PostgreSQL/pgvector + Next.js 구조를 전제로 한 주차별 칸반 운영안입니다.

원칙

1. 계산식/스키마를 먼저 고정합니다.
2. 파이프라인을 End-to-End로 빠르게 1회 관통합니다.
3. 마지막 주는 품질/재현성/감사로그에 집중합니다.

---

## 칸반 보드 컬럼 정의

* Backlog: 이번 주에 반드시 다뤄야 하나 아직 착수 전
* In Progress: 진행 중(WIP 제한: 파트별 2개)
* Review/QA: PR 리뷰, 테스트, 샘플 리포트 검증
* Done: 수용 기준 충족(데모 가능)

---

## Week 1: 계산식/데이터/스키마 고정 + End-to-End 1회 관통

| Backlog                                                    | In Progress                                                            | Review/QA                       | Done                |
| ---------------------------------------------------------- | ---------------------------------------------------------------------- | ------------------------------- | ------------------- |
| 요구사항 1페이지 명세(입력/출력/지표 정의, 5대 핵심 이슈 구조)                     | 중대성 평가 계산식 확정: 영향(긍/부정), 이해관계자, 산출지표, 영향추정지표 → Score 모델링               | 계산식 단위 테스트(엣지케이스: 결측/0/역수/스케일링) | 계산식 버전 v0.1(문서+테스트) |
| DB 스키마 설계: IssuePool, Evidence, ScoreRun, Report, AuditLog | PostgreSQL+pgvector 스키마 생성 및 마이그레이션                                    | DB 인덱스/쿼리 플랜 확인(TopK, 필터)       | 기본 CRUD 동작          |
| RAG 데이터 수집/정리: ESG 보고서, 정책, 인증, 내부 문서 샘플                   | 임베딩 파이프라인(청크/메타데이터/업서트)                                                | 검색 품질 점검(샘플 질문 20개)             | 벡터 검색 1차 품질 OK      |
| LangGraph 스타 토폴로지 노드 역할 확정                                 | LangGraph 골격 구현: Orchestrator → (EXAONE: 요약/근거추출) + (KoELECTRA: 분류/판정) | 노드 입출력 스키마 검증(JSON schema)      | 그래프 1회 실행 성공        |
| FastAPI API 계약(Next.js 연동)                                 | API 스켈레톤(평가 실행/결과 조회/증빙 업로드)                                           | Swagger/OpenAPI 확인              | FE에서 API 호출 성공(더미)  |

Week 1 산출물(데모)
문서 업로드 → 벡터화 → 특정 이슈 1개 근거 추출/분류 → 계산식으로 점수 산출이 1회 끝까지 돌아갑니다.

---

## Week 2: 모델 파이프라인 실전화 + 화면/리포트 + 재현성

| Backlog                                    | In Progress                                                                   | Review/QA                       | Done              |
| ------------------------------------------ | ----------------------------------------------------------------------------- | ------------------------------- | ----------------- |
| 이슈 풀(주제) 템플릿 5개 고정(기후/윤리경영/인권/개인정보/안전보건 등) | 이슈별 자동 평가 파이프라인: (근거 TopK) → EXAONE 근거요약 → KoELECTRA 판정(긍/부정/리스크 레벨) → 계산식 반영 | 샘플 10개 기업 데이터로 결과 타당성 리뷰        | 5개 이슈 일괄 평가 성공    |
| 근거(문장/표) → 지표 매핑 룰/프롬프트 정교화                | 프롬프트/룰 튜닝: 근거 인용(문서ID/페이지/청크ID), 추론 금지 가드                                     | Hallucination 체크(근거 없는 주장 0 목표) | 인용 기반 답변 준수       |
| Next.js 화면: 핵심 이슈 분석 테이블/세부 드릴다운           | UI 구현: 이슈 리스트(점수/레벨), 이해관계자, 산출지표, 영향추정지표, 근거 카드                              | UX 리뷰(필수: 근거 클릭 시 원문 흐름)        | 1차 화면 완성          |
| 리포트 출력(JSON/PDF 초안)                        | 리포트 생성기: 평가 결과 + 근거 + 계산식 버전 + 실행ID 포함                                        | 샘플 리포트 3개 검토                    | JSON 리포트 v0.1     |
| 실행 이력/감사로그                                 | ScoreRun/AuditLog 적재: 누가, 언제, 어떤 입력으로, 어떤 모델/프롬프트/계산식 버전으로 실행했는지              | 재실행 동일 결과 확인(Determinism 최대화)   | 실행 이력 조회 화면/엔드포인트 |

Week 2 산출물(데모)
기업 1개를 넣으면 5개 핵심 이슈가 표 형태로 자동 평가되고, 각 셀은 근거로 클릭 추적 가능해집니다.

---

## Week 3: 품질/운영성(속도·비용·오류) + 배포 + 최종 데모

| Backlog                | In Progress                                                   | Review/QA               | Done                |
| ---------------------- | ------------------------------------------------------------- | ----------------------- | ------------------- |
| 평가 정확도/일관성 개선(라벨링 최소셋) | 골든셋 50~100건 구성: 이슈별 정답(레벨/근거) 최소 라벨링                          | Precision/Recall 간이 리포트 | 기준 성능 달성(예: 레벨 일치율) |
| 비용/속도 최적화              | 캐싱/배치/토큰 절감: 검색 TopK 튜닝, 요약 길이 제한, 중복 근거 제거                   | 평균 응답시간/비용 측정           | 목표 SLO 충족           |
| 예외/실패 처리               | 실패 시나리오: 문서 품질 낮음, 근거 부족, 분류 불가, 계산식 결측                       | 재시도/폴백(룰 기반) 테스트        | 안정성 확보              |
| 보안/권한                  | 테넌트/프로젝트 단위 권한, 문서 접근 제어, API rate limit                      | 취약점 체크리스트               | 최소 보안선 충족           |
| 배포                     | Docker compose/CI: Next.js + API + DB(+pgvector) 구성, 환경변수 문서화 | 스테이징 배포 검증              | 프로덕션/데모 배포          |
| 최종 데모 시나리오             | 데모 스크립트: 업로드 → 평가 → 근거 → 시정조치 필요 → 리포트 출력                     | 리허설 2회                  | 납품/발표 준비 완료         |

Week 3 산출물(데모)
실사용 흐름 + 실행이력/감사로그 + 리포트까지 완성된 MVP입니다.

---

## 역할 분리(스타 토폴로지 기준)

* KoELECTRA(Decider/Gateway)

  * 이슈 분류, 리스크 레벨, 준수 여부 판정
  * 규칙 기반 폴백 트리거

* EXAONE(Reader/Analyst)

  * 근거 추출/요약
  * 이해관계자-지표 매핑 설명
  * 반드시 인용 첨부(문서ID/페이지/청크ID)

* Policy 노드(규칙/계산식)

  * 계산식을 코드로 고정하고 버전 관리
  * 모델 출력은 “입력값”만 제공하고 최종 점수는 Policy에서 계산

* Notify/Report

  * 결과를 표준 포맷(JSON/PDF)으로 출력
  * 실행 이력 저장 및 조회 제공

---

## PM 운영 규칙(3주 프로젝트)

* WIP 2개 제한, PR은 24시간 내 머지
* 근거 없는 문장은 실패로 간주(인용 없으면 출력 금지)
* 계산식/스키마는 Week 1에 잠그고, Week 2부터 변경 시 버전만 올립니다(하위호환 유지)

---

## 다음 작업 제안

첨부한 “핵심 이슈 분석” 테이블을 기준으로, 아래 2가지를 고정하면 Week 1의 명세가 빠르게 완성됩니다.

* 입력/출력 JSON 스키마(이슈 1건 단위)
* 계산식 코드 인터페이스(Policy 노드 함수 시그니처)

---

